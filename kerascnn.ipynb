{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wTELPMsGCHx"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qm4mZ9JpGKWn"
      },
      "outputs": [],
      "source": [
        "import pathlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAmrFUCyGSw4"
      },
      "outputs": [],
      "source": [
        "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "data_dir = tf.keras.utils.get_file('flower_photos.tar', origin=dataset_url, extract=True)\n",
        "print(data_dir)\n",
        "data_dir = pathlib.Path(data_dir).with_suffix('')\n",
        "print(data_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhsXR9LSKGaj"
      },
      "outputs": [],
      "source": [
        "image_count=len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wuEl0GbVKp8L"
      },
      "outputs": [],
      "source": [
        "print((list(data_dir.glob('*/*.jpg'))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTgJL34lLCFO"
      },
      "outputs": [],
      "source": [
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfFBo1dNLHkh"
      },
      "outputs": [],
      "source": [
        "#READ IMAGE\n",
        "image=cv2.imread('/root/.keras/datasets/flower_photos/roses/20409866779_ac473f55e0_m.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dyR5Ut6Lu4S"
      },
      "outputs": [],
      "source": [
        "print(image.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "em58QOzNLu7j"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8gBOiftGa5V"
      },
      "outputs": [],
      "source": [
        "roses=list(data_dir.glob('roses/*'))# glob - function as the pattern based searching in the given code\n",
        "PIL.Image.open(str(roses[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Chwof3gKGa8r"
      },
      "outputs": [],
      "source": [
        "PIL.Image.open(str(roses[2]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvH6TjwhGa_u"
      },
      "outputs": [],
      "source": [
        "tulips=list(data_dir.glob('tulips/*'))\n",
        "PIL.Image.open(str(tulips[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bmRMxYmGbDT"
      },
      "outputs": [],
      "source": [
        "PIL.Image.open(str(tulips[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPYRatWlGbKZ"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OuYFFKmMGbUj"
      },
      "outputs": [],
      "source": [
        "train_ds=tf.keras.utils.image_dataset_from_directory(\n",
        "data_dir,validation_split=0.2,subset=\"training\",seed=123,image_size=(img_height,img_width),batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hdao3tmoy8S"
      },
      "outputs": [],
      "source": [
        "val_ds=tf.keras.utils.image_dataset_from_directory(\n",
        "data_dir,validation_split=0.2,subset=\"validation\",seed=123,image_size=(img_height,img_width),batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bRa7coNqiMB"
      },
      "outputs": [],
      "source": [
        "class_names=train_ds.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A667Y9a9qxgv"
      },
      "outputs": [],
      "source": [
        "class_names1=val_ds.class_names\n",
        "print(class_names1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mvHOv38rQvL"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(20):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhjkD4UTskV6"
      },
      "outputs": [],
      "source": [
        "for image_batch,labels_batch in train_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVz5rPIHt6cC"
      },
      "outputs": [],
      "source": [
        "normalization_layer = layers.Rescaling(1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhs2grCFt_bR"
      },
      "outputs": [],
      "source": [
        "num_classes = len(class_names)\n",
        "print(num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqshiyY_uHFq"
      },
      "outputs": [],
      "source": [
        "model= Sequential([\n",
        "    layers.Rescaling(1./255,input_shape=(img_height, img_width, 3)),\n",
        "    layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(num_classes)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAtUmbqz0nBy"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpvRhF9hxqPD"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy\n",
        "               (from_logits=True),metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnwdNLHl1dCy"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bt2q9stg1hrG"
      },
      "outputs": [],
      "source": [
        "epochs=10\n",
        "history=model.fit(\n",
        "    train_ds,validation_data=val_ds,\n",
        "    epochs=epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mF40p_k228za"
      },
      "outputs": [],
      "source": [
        "acc=history.history['accuracy']\n",
        "val_acc=history.history['val_accuracy']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLPBSPm13W6b"
      },
      "outputs": [],
      "source": [
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJCG9IBm3vZ6"
      },
      "outputs": [],
      "source": [
        "epochs_range=range(epochs)\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9rRC8un5_Ae"
      },
      "outputs": [],
      "source": [
        "model1= Sequential([\n",
        "    layers.Rescaling(1./255),\n",
        "    layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(num_classes, name=\"outputs\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPf3Hy8d6lJ2"
      },
      "outputs": [],
      "source": [
        "model1.compile(optimizer='adam',\n",
        "loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-aSCkMD7M64"
      },
      "outputs": [],
      "source": [
        "epochs=10\n",
        "history1=model1.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kb2SbWD08EPP"
      },
      "outputs": [],
      "source": [
        "acc = history1.history['accuracy']\n",
        "val_acc = history1.history['val_accuracy']\n",
        "loss = history1.history['loss']\n",
        "val_loss = history1.history['val_loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kR6x2pEv8Ill"
      },
      "outputs": [],
      "source": [
        "epochs_range = range(epochs)\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = keras.Sequential([\n",
        "  layers.RandomFlip(\"horizontal\",\n",
        "  input_shape=(img_height,img_width,3)),\n",
        "  layers.RandomRotation(0.1),\n",
        "  layers.RandomZoom(0.1),\n",
        "])"
      ],
      "metadata": {
        "id": "zc5Z0c5Vy7je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, _ in train_ds.take(1):\n",
        " for i in range(9):\n",
        "  augmented_images = data_augmentation(images)\n",
        "  ax = plt.subplot(3, 3, i + 1)\n",
        "  plt.imshow(augmented_images[1].numpy().astype(\"uint8\"))\n",
        "  plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "aiAXs1ni8Rnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential([\n",
        "data_augmentation,\n",
        "layers.Rescaling(1./255),\n",
        "layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "layers.MaxPooling2D(),\n",
        "layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "layers.MaxPooling2D(),\n",
        "layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "layers.MaxPooling2D(),\n",
        "layers.Dropout(0.2),\n",
        "layers.Flatten(),\n",
        "layers.Dense(128, activation='relu'),\n",
        "layers.Dense(num_classes, name=\"outputs\")\n",
        "])"
      ],
      "metadata": {
        "id": "cZXmNCjO0EhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(optimizer='adam',\n",
        "\n",
        "loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ksbZLNkm9NRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 15\n",
        "history3 = model2.fit(\n",
        "train_ds,\n",
        "validation_data=val_ds,\n",
        "epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "bmawCvPI9UO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history3.history['accuracy']\n",
        "val_acc = history3.history['val_accuracy']\n",
        "loss = history3.history['loss']\n",
        "val_loss = history3.history['val_loss']"
      ],
      "metadata": {
        "id": "xX6Y3EYqGuun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_range = range(epochs)\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-XqT2IQfGu_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "import numpy as np\n",
        "np.random.seed(1000)\n",
        "#instantiate an empty model\n"
      ],
      "metadata": {
        "id": "nZLzl_q1B4zk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "img_height = 227\n",
        "img_width = 227"
      ],
      "metadata": {
        "id": "M46RKssYByIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "#first convolutional layer\n",
        "model.add(Conv2D(filters=96, input_shape=(227,227,3), kernel_size=(11,11), strides=(4,4), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "#max pooling\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
        "#2nd convolutional layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "#max pooling\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
        "#3rd convolutional layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "#4th convolutional layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "#5th convolutional layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "#max pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "#passing it to a fully connected layer\n",
        "model.add(Flatten())\n",
        "#1 st fully connected layer\n",
        "model.add(Dense(4096,input_shape=(227*227*3,)))\n",
        "model.add(Activation('relu'))\n",
        "#add dropout to prevent overfitting\n",
        "model.add(Dropout(0.4))\n",
        "#2nd fully connected layer\n",
        "model.add(Dense(4096))\n",
        "model.add(Activation('relu'))\n",
        "# add dropout\n",
        "model.add(Dropout(0.4))\n",
        "#3rd fully connected layer\n",
        "model.add(Dense(1000))\n",
        "model.add(Activation('relu'))\n",
        "#add dropout\n",
        "model.add(Dropout(0.4))\n",
        "#output layer\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "d1iAkR99B5AE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "fCoO_zR3B5DP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "h6Om2_jzB5Gr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=20\n",
        "history3=model2.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "mPbK-AnpDRz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Conv2D(input_shape=(300,300,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model2.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "model2.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "model2.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "model2.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "model2.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "model2.add(Conv2D(filters=1024, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(Conv2D(filters=1024, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(Conv2D(filters=1024, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(units=5000,input_shape=(300,300,3),activation=\"relu\"))\n",
        "model.add(Dropout(0.4))\n",
        "model2.add(Dense(units=5000,activation=\"relu\"))\n",
        "model2.add(Dense(units=2, activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "sAc3DeSTItLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.compile(optimizer='adam',\n",
        "loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "JATUeIgTMUN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.summary()"
      ],
      "metadata": {
        "id": "Y7x4Z1FYJETR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 2\n",
        "history3 = model1.fit(\n",
        "train_ds,\n",
        "validation_data=val_ds,\n",
        "epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "exD0N7GOMHM5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}